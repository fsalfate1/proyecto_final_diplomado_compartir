{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persistencia con Neon (Postgres)\n",
    "\n",
    "Este notebook muestra un flujo minimo de LangGraph con persistencia en Neon.\n",
    "No usa memoria local; todo se guarda en Postgres.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f54c0004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: psycopg[binary]\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Instalacion (si hace falta)\n",
    "%pip install -q langgraph langchain_openai langchain_core langchain_community langgraph-checkpoint-postgres python-dotenv psycopg[binary]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf084136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar variables de entorno\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "database_url = os.environ.get(\"DATABASE_URL\")\n",
    "if not database_url:\n",
    "    raise RuntimeError(\"Define DATABASE_URL en .env para usar Neon/Postgres\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70552a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones basicas\n",
    "from typing import TypedDict, List, Dict, Any, Annotated\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph, START, END, add_messages\n",
    "from langgraph.checkpoint.postgres import PostgresSaver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3a60a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1, max_tokens=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a3eac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estado personalizado\n",
    "class EstadoPersonalizado(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "    nombre_usuario: str\n",
    "    intereses: List[str]\n",
    "    nivel_experiencia: str\n",
    "    numero_sesion: int\n",
    "    preguntas_realizadas: int\n",
    "    preferencias: Dict[str, Any]\n",
    "\n",
    "def agente_personalizado(state: EstadoPersonalizado) -> EstadoPersonalizado:\n",
    "    nombre = state.get(\"nombre_usuario\", \"Estudiante\")\n",
    "    intereses = state.get(\"intereses\", [])\n",
    "    nivel = state.get(\"nivel_experiencia\", \"principiante\")\n",
    "    sesion = state.get(\"numero_sesion\", 0) + 1\n",
    "    preguntas = state.get(\"preguntas_realizadas\", 0) + 1\n",
    "\n",
    "    system_prompt = (\n",
    "        f\"Eres un tutor de IA. Nombre: {nombre}. Nivel: {nivel}. \"\n",
    "        f\"Intereses: {intereses if intereses else 'no definidos'}.\"\n",
    "    )\n",
    "\n",
    "    messages = [SystemMessage(content=system_prompt)] + state[\"messages\"]\n",
    "    respuesta = llm.invoke(messages)\n",
    "\n",
    "    ultimo_mensaje = state[\"messages\"][-1].content if state[\"messages\"] else \"\"\n",
    "    nuevos_intereses = intereses.copy()\n",
    "    for interes in [\"machine learning\", \"python\", \"datos\"]:\n",
    "        if interes in ultimo_mensaje.lower() and interes not in nuevos_intereses:\n",
    "            nuevos_intereses.append(interes)\n",
    "\n",
    "    return {\n",
    "        \"messages\": [respuesta],\n",
    "        \"nombre_usuario\": nombre,\n",
    "        \"intereses\": nuevos_intereses,\n",
    "        \"nivel_experiencia\": nivel,\n",
    "        \"numero_sesion\": sesion,\n",
    "        \"preguntas_realizadas\": preguntas,\n",
    "        \"preferencias\": state.get(\"preferencias\", {}),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2442cfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Hola, Fabián! Es genial que te gusten los autos. Hay tanto que explorar en ese mundo, desde la ingeniería y el diseño hasta la historia de los automóviles y las carreras. ¿Tienes algún tipo de auto favorito o algún aspecto específico que te interese más?\n"
     ]
    }
   ],
   "source": [
    "# Grafo con persistencia en Neon\n",
    "builder = StateGraph(EstadoPersonalizado)\n",
    "builder.add_node(\"tutor\", agente_personalizado)\n",
    "builder.add_edge(START, \"tutor\")\n",
    "builder.add_edge(\"tutor\", END)\n",
    "\n",
    "\n",
    "telefono = \"+56982430581\"  # Numero de telefono como identificador unico\n",
    "\n",
    "with PostgresSaver.from_conn_string(database_url) as checkpointer:\n",
    "    checkpointer.setup()\n",
    "    grafo = builder.compile(checkpointer=checkpointer)\n",
    "\n",
    "    entrada = {\"messages\": [HumanMessage(content=\"Hola me llamo Fabian, Me gusta los autos\")] }\n",
    "    config = {\"configurable\": {\"thread_id\": telefono}}\n",
    "    resultado = grafo.invoke(entrada, config=config)\n",
    "    print(resultado[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4fc76d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Hola, Fabián! Hasta ahora, me has mencionado que te gustan los autos. Si quieres, podemos explorar más sobre ese interés o descubrir otros que puedan gustarte. ¿Te gustaría hablar sobre algún tipo específico de auto, como deportivos, clásicos, eléctricos, o tal vez sobre la mecánica y el mantenimiento? También podríamos hablar de otros temas si te interesa. ¡Dime qué piensas!\n"
     ]
    }
   ],
   "source": [
    "# Grafo con persistencia en Neon\n",
    "builder = StateGraph(EstadoPersonalizado)\n",
    "builder.add_node(\"tutor\", agente_personalizado)\n",
    "builder.add_edge(START, \"tutor\")\n",
    "builder.add_edge(\"tutor\", END)\n",
    "\n",
    "\n",
    "telefono = \"+56982430581\"  \n",
    "\n",
    "with PostgresSaver.from_conn_string(database_url) as checkpointer:\n",
    "    checkpointer.setup()\n",
    "    grafo = builder.compile(checkpointer=checkpointer)\n",
    "\n",
    "    entrada = {\"messages\": [HumanMessage(content=\"Hola me llamo Fabian, cuales son mis intereses?\")] }\n",
    "    config = {\"configurable\": {\"thread_id\": telefono}}\n",
    "    resultado = grafo.invoke(entrada, config=config)\n",
    "    print(resultado[\"messages\"][-1].content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
