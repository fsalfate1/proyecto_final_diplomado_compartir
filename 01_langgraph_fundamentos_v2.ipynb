{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ LangGraph: Fundamentos y Conceptos Basicos\n",
    "\n",
    "## üìö Objetivos de Aprendizaje\n",
    "\n",
    "En este notebook aprenderas:\n",
    "- ‚úÖ Configurar LangGraph correctamente\n",
    "- ‚úÖ Entender StateGraph, nodos y aristas\n",
    "- ‚úÖ Implementar herramientas personalizadas\n",
    "- ‚úÖ Manejar persistencia y estado\n",
    "- ‚úÖ Crear tus primeros agentes multi-agente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üõ†Ô∏è 1. Configuracion del Entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "‚úÖ Todas las dependencias instaladas correctamente\n"
     ]
    }
   ],
   "source": [
    "# Instalacion de dependencias\n",
    "!pip install -q langgraph langchain_openai langchain_core langchain_community\n",
    "!pip install -q langchain-google-genai langgraph-checkpoint-sqlite langgraph-checkpoint-postgres\n",
    "!pip install -q python-dotenv matplotlib networkx\n",
    "\n",
    "print(\"‚úÖ Todas las dependencias instaladas correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API Key configurada desde variables de entorno\n"
     ]
    }
   ],
   "source": [
    "# Configuracion de API Keys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Cargar variables de entorno\n",
    "load_dotenv()\n",
    "\n",
    "# Para Google Colab\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
    "    print(\"‚úÖ API Key configurada desde Google Colab\")\n",
    "except:\n",
    "    \n",
    "    if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "        print(\"‚ö†Ô∏è Configura tu OPENAI_API_KEY\")\n",
    "        # Descomenta la siguiente linea y agrega tu API key\n",
    "        # os.environ[\"OPENAI_API_KEY\"] = \"tu-api-key-aqui\"\n",
    "    else:\n",
    "        print(\"‚úÖ API Key configurada desde variables de entorno\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "no pq wrapper available.\nAttempts made:\n- couldn't import psycopg 'c' implementation: No module named 'psycopg_c'\n- couldn't import psycopg 'binary' implementation: No module named 'psycopg_binary'\n- couldn't import psycopg 'python' implementation: libpq library not found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanggraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprebuilt\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_react_agent\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanggraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcheckpoint\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msqlite\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SqliteSaver\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanggraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcheckpoint\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpostgres\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PostgresSaver\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanggraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcheckpoint\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmemory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MemorySaver\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Importaciones completadas\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Diplomando IA/Archivos/M3/Proyecto_Final_V2/.venv/lib/python3.13/site-packages/langgraph/checkpoint/postgres/__init__.py:20\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanggraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcheckpoint\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     11\u001b[39m     WRITES_IDX_MAP,\n\u001b[32m     12\u001b[39m     ChannelVersions,\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m     get_serializable_checkpoint_metadata,\n\u001b[32m     18\u001b[39m )\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanggraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcheckpoint\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mserde\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SerializerProtocol\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpsycopg\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Capabilities, Connection, Cursor, Pipeline\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpsycopg\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrows\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DictRow, dict_row\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpsycopg\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mjson\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Jsonb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Diplomando IA/Archivos/M3/Proyecto_Final_V2/.venv/lib/python3.13/site-packages/psycopg/__init__.py:9\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Copyright (C) 2020 The Psycopg Team\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pq  \u001b[38;5;66;03m# noqa: F401 import early to stabilize side effects\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dbapi20, postgres, types\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_tpc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Xid\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Diplomando IA/Archivos/M3/Proyecto_Final_V2/.venv/lib/python3.13/site-packages/psycopg/pq/__init__.py:116\u001b[39m\n\u001b[32m    107\u001b[39m         sattempts = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattempt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m attempts)\n\u001b[32m    108\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m    109\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[32m    110\u001b[39m \u001b[33mno pq wrapper available.\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[33mAttempts made:\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;132;01m{\u001b[39;00msattempts\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    113\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m \u001b[43mimport_from_libpq\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m __all__ = (\n\u001b[32m    119\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mConnStatus\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    120\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mPipelineStatus\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    135\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mversion_pretty\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    136\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Diplomando IA/Archivos/M3/Proyecto_Final_V2/.venv/lib/python3.13/site-packages/psycopg/pq/__init__.py:108\u001b[39m, in \u001b[36mimport_from_libpq\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    106\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    107\u001b[39m         sattempts = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattempt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m attempts)\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m    109\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[32m    110\u001b[39m \u001b[33mno pq wrapper available.\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[33mAttempts made:\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;132;01m{\u001b[39;00msattempts\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    113\u001b[39m         )\n",
      "\u001b[31mImportError\u001b[39m: no pq wrapper available.\nAttempts made:\n- couldn't import psycopg 'c' implementation: No module named 'psycopg_c'\n- couldn't import psycopg 'binary' implementation: No module named 'psycopg_binary'\n- couldn't import psycopg 'python' implementation: libpq library not found"
     ]
    }
   ],
   "source": [
    "# Importaciones basicas\n",
    "import json\n",
    "import time\n",
    "import sqlite3\n",
    "from typing import Literal, List, Dict, Any, Optional, TypedDict, Annotated\n",
    "from datetime import datetime\n",
    "\n",
    "# LangChain y LangGraph\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, BaseMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# LangGraph core\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END, add_messages\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "print(\"‚úÖ Importaciones completadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Parece que est√°s mencionando un mensaje que indica que una configuraci√≥n se ha realizado con √©xito. Si necesitas ayuda con algo espec√≠fico relacionado con la configuraci√≥n, no dudes en darme m√°s detalles y estar√© encantado de ayudarte.\n"
     ]
    }
   ],
   "source": [
    "# Configurar modelo principal\n",
    "try:\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4o-mini\",  # Modelo mas economico para aprendizaje\n",
    "        temperature=0.1,\n",
    "        max_tokens=1000\n",
    "    )\n",
    "    \n",
    "    # Prueba de configuracion\n",
    "    test_response = llm.invoke([HumanMessage(content=\"Di: 'Configuracion exitosa'\")])  \n",
    "    print(f\"‚úÖ {test_response.content}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    print(\"Verifica tu API key y conexion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üß† 2. Conceptos Fundamentales de LangGraph\n",
    "\n",
    "## ¬øQue es LangGraph?\n",
    "\n",
    "LangGraph es una biblioteca para construir **sistemas multi-agente** usando grafos. Los conceptos clave son:\n",
    "\n",
    "- **üîó StateGraph**: El grafo que define el flujo de ejecucion\n",
    "- **üì¶ Estado**: Informacion que fluye entre nodos (como `MessagesState`)\n",
    "- **üéØ Nodos**: Funciones que procesan el estado\n",
    "- **‚û°Ô∏è Aristas**: Conexiones que definen el flujo\n",
    "- **üé≠ Agentes**: Funciones inteligentes que pueden usar herramientas\n",
    "\n",
    "## Diagrama Conceptual\n",
    "\n",
    "```\n",
    "[Estado Inicial] ‚Üí [Nodo 1] ‚Üí [Nodo 2] ‚Üí [Estado Final]\n",
    "                      ‚Üì         ‚Üì\n",
    "                 [Herramientas] [Decisiones]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Funcion de agente definida\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo 1: Tu primer grafo simple\n",
    "def mi_primer_agente(state: MessagesState) -> MessagesState:\n",
    "    \"\"\"\n",
    "    Un agente simple que procesa mensajes.\n",
    "    \n",
    "    Args:\n",
    "        state: Estado actual con mensajes\n",
    "        \n",
    "    Returns:\n",
    "        Estado actualizado con nueva respuesta\n",
    "    \"\"\"\n",
    "    print(\"ü§ñ Mi primer agente esta trabajando...\")\n",
    "    \n",
    "    # Crear prompt del sistema\n",
    "    system_prompt = \"Eres un asistente educativo que explica conceptos de IA de manera simple.\"\n",
    "\n",
    "    print(state)\n",
    "    \n",
    "    # Construir mensajes para el LLM\n",
    "    messages = [SystemMessage(content=system_prompt)] + state[\"messages\"]\n",
    "    \n",
    "    # Obtener respuesta\n",
    "    respuesta = llm.invoke(messages)\n",
    "    \n",
    "    print(f\"‚úÖ Agente completo su trabajo\")\n",
    "    \n",
    "    # Retornar estado actualizado\n",
    "    return {\"messages\": [respuesta]}\n",
    "\n",
    "print(\"‚úÖ Funcion de agente definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è Construyendo mi primer grafo...\n",
      "‚úÖ ¬°Tu primer grafo esta listo!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construir tu primer grafo\n",
    "from IPython.display import Image\n",
    "\n",
    "print(\"üèóÔ∏è Construyendo mi primer grafo...\")\n",
    "\n",
    "# 1. Crear el builder del grafo\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# 2. Anadir nodo\n",
    "builder.add_node(\"mi_agente\", mi_primer_agente)\n",
    "\n",
    "# 3. Definir flujo: START ‚Üí mi_agente ‚Üí END\n",
    "builder.add_edge(START, \"mi_agente\")\n",
    "builder.add_edge(\"mi_agente\", END)\n",
    "\n",
    "# 4. Compilar grafo\n",
    "mi_primer_grafo = builder.compile()\n",
    "\n",
    "print(\"‚úÖ ¬°Tu primer grafo esta listo!\")\n",
    "\n",
    "Image(mi_primer_grafo.get_graph().draw_mermaid_png())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ PROBANDO MI PRIMER GRAFO\n",
      "========================================\n",
      "‚ùì Pregunta: ¬øQue es un grafo en LangGraph?\n",
      "\n",
      "üîÑ Ejecutando grafo...\n",
      "ü§ñ Mi primer agente esta trabajando...\n",
      "{'messages': [HumanMessage(content='¬øQue es un grafo en LangGraph?', additional_kwargs={}, response_metadata={}, id='ff662f6a-7f86-43a9-88b1-7696c2f7e8ad')]}\n",
      "‚úÖ Agente completo su trabajo\n",
      "\n",
      "ü§ñ Respuesta:\n",
      "[HumanMessage(content='¬øQue es un grafo en LangGraph?', additional_kwargs={}, response_metadata={}, id='ff662f6a-7f86-43a9-88b1-7696c2f7e8ad'), AIMessage(content='Un grafo en LangGraph es una estructura que se utiliza para representar relaciones entre diferentes elementos, como palabras, frases o conceptos. En terminos simples, un grafo esta compuesto por nodos (que representan los elementos) y aristas (que representan las conexiones o relaciones entre esos elementos).\\n\\nEn el contexto de LangGraph, los grafos pueden ayudar a modelar y entender como se relacionan diferentes partes del lenguaje, lo que puede ser util para tareas como el procesamiento del lenguaje natural, la generacion de texto o la comprension de significados. Por ejemplo, un grafo podria mostrar como una palabra se relaciona con sinonimos, antonimos o palabras que suelen aparecer juntas en un texto.\\n\\nAsi que, en resumen, un grafo en LangGraph es una forma de visualizar y analizar las conexiones entre diferentes elementos del lenguaje.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 168, 'prompt_tokens': 35, 'total_tokens': 203, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C64WQFlVFSTKZhbqPj4500bKFoMvD', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c9107cd5-c647-4c0e-a91e-8238bb2c51de-0', usage_metadata={'input_tokens': 35, 'output_tokens': 168, 'total_tokens': 203, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "\n",
      "========================================\n",
      "üéâ ¬°Felicitaciones! Has ejecutado tu primer grafo LangGraph\n"
     ]
    }
   ],
   "source": [
    "# Probar tu primer grafo\n",
    "print(\"üß™ PROBANDO MI PRIMER GRAFO\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Entrada del usuario\n",
    "entrada = {\n",
    "    \"messages\": [HumanMessage(content=\"¬øQue es un grafo en LangGraph?\")]\n",
    "}\n",
    "\n",
    "print(f\"‚ùì Pregunta: {entrada['messages'][0].content}\")\n",
    "print(\"\\nüîÑ Ejecutando grafo...\")\n",
    "\n",
    "# Ejecutar\n",
    "resultado = mi_primer_grafo.invoke(entrada)\n",
    "\n",
    "print(f\"\\nü§ñ Respuesta:\")\n",
    "print(resultado[\"messages\"])\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"üéâ ¬°Felicitaciones! Has ejecutado tu primer grafo LangGraph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üõ†Ô∏è 3. Herramientas (@tool) - Extendiendo Capacidades\n",
    "\n",
    "Las herramientas permiten que los agentes interactuen con el mundo exterior:\n",
    "- üåê APIs web\n",
    "- üóÑÔ∏è Bases de datos  \n",
    "- üßÆ Calculadoras\n",
    "- üìä Analisis de datos\n",
    "- üìß Envio de emails\n",
    "\n",
    "## ¬øComo Funcionan?\n",
    "\n",
    "1. **Definir**: Usar decorator `@tool`\n",
    "2. **Describir**: Docstring clara para que el agente entienda cuando usarla\n",
    "3. **Integrar**: Pasar herramientas al agente\n",
    "4. **Ejecutar**: El agente decide cuando y como usar cada herramienta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõ†Ô∏è Herramientas creadas:\n",
      "  ‚úÖ calculadora_simple\n",
      "  ‚úÖ obtener_fecha_actual\n",
      "  ‚úÖ buscar_definicion\n",
      "  ‚úÖ generar_numero_aleatorio\n",
      "\n",
      "üìä Total: 4 herramientas disponibles\n"
     ]
    }
   ],
   "source": [
    "# Crear herramientas basicas\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "@tool\n",
    "def calculadora_simple(expresion: str) -> str:\n",
    "    \"\"\"\n",
    "    Realiza calculos matematicos basicos.\n",
    "    \n",
    "    Args:\n",
    "        expresion: Expresion matematica (ej: \"2 + 3 * 4\")\n",
    "        \n",
    "    Returns:\n",
    "        Resultado del calculo\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Solo permitir operaciones seguras\n",
    "        allowed_chars = set(\"0123456789+-*/(). \")\n",
    "        if not all(c in allowed_chars for c in expresion):\n",
    "            return \"Error: Solo numeros y operadores basicos permitidos\"\n",
    "        \n",
    "        resultado = eval(expresion)\n",
    "        return f\"El resultado de '{expresion}' es: {resultado}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error al calcular: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def obtener_fecha_actual() -> str:\n",
    "    \"\"\"\n",
    "    Obtiene la fecha y hora actual.\n",
    "    \n",
    "    Returns:\n",
    "        Fecha y hora actuales\n",
    "    \"\"\"\n",
    "    ahora = datetime.now()\n",
    "    return f\"Hoy es {ahora.strftime('%Y-%m-%d')} y son las {ahora.strftime('%H:%M:%S')}\"\n",
    "\n",
    "@tool\n",
    "def buscar_definicion(termino: str) -> str:\n",
    "    \"\"\"\n",
    "    Busca la definicion de terminos tecnicos de IA.\n",
    "    \n",
    "    Args:\n",
    "        termino: Termino a definir\n",
    "        \n",
    "    Returns:\n",
    "        Definicion del termino\n",
    "    \"\"\"\n",
    "    definiciones = {\n",
    "        \"machine learning\": \"Subcampo de la IA que permite a las maquinas aprender patrones de los datos sin programacion explicita.\",\n",
    "        \"deep learning\": \"Tecnica de ML que usa redes neuronales profundas para aprender representaciones complejas.\",\n",
    "        \"llm\": \"Large Language Model - Modelo de lenguaje grande entrenado con enormes cantidades de texto.\",\n",
    "        \"grafo\": \"Estructura de datos que consiste en nodos conectados por aristas.\",\n",
    "        \"agente\": \"Sistema de IA que puede percibir su entorno y tomar acciones para lograr objetivos.\"\n",
    "    }\n",
    "    \n",
    "    termino_lower = termino.lower()\n",
    "    if termino_lower in definiciones:\n",
    "        return f\"üìö {termino}: {definiciones[termino_lower]}\"\n",
    "    else:\n",
    "        return f\"ü§î No encontre definicion para '{termino}'. Terminos disponibles: {', '.join(definiciones.keys())}\"\n",
    "\n",
    "@tool  \n",
    "def generar_numero_aleatorio(minimo: int = 1, maximo: int = 100) -> str:\n",
    "    \"\"\"\n",
    "    Genera un numero aleatorio en un rango.\n",
    "    \n",
    "    Args:\n",
    "        minimo: Valor minimo (default: 1)\n",
    "        maximo: Valor maximo (default: 100)\n",
    "        \n",
    "    Returns:\n",
    "        Numero aleatorio generado\n",
    "    \"\"\"\n",
    "    numero = random.randint(minimo, maximo)\n",
    "    return f\"üé≤ Numero aleatorio entre {minimo} y {maximo}: {numero}\"\n",
    "\n",
    "# Lista de herramientas\n",
    "mis_herramientas = [\n",
    "    calculadora_simple,\n",
    "    obtener_fecha_actual,\n",
    "    buscar_definicion,\n",
    "    generar_numero_aleatorio\n",
    "]\n",
    "\n",
    "print(\"üõ†Ô∏è Herramientas creadas:\")\n",
    "for herramienta in mis_herramientas:\n",
    "    print(f\"  ‚úÖ {herramienta.name}\")\n",
    "print(f\"\\nüìä Total: {len(mis_herramientas)} herramientas disponibles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Creando agente con herramientas...\n",
      "‚úÖ Agente con herramientas creado\n",
      "üéØ Listo para responder preguntas y usar herramientas\n"
     ]
    }
   ],
   "source": [
    "# Crear agente con herramientas\n",
    "print(\"ü§ñ Creando agente con herramientas...\")\n",
    "\n",
    "# Prompt personalizado para el agente\n",
    "system_prompt = \"\"\"\n",
    "Eres un tutor de IA inteligente con acceso a herramientas especializadas.\n",
    "\n",
    "HERRAMIENTAS DISPONIBLES:\n",
    "- calculadora_simple: Para hacer calculos matematicos\n",
    "- obtener_fecha_actual: Para saber la fecha y hora\n",
    "- buscar_definicion: Para definir terminos tecnicos\n",
    "- generar_numero_aleatorio: Para generar numeros aleatorios\n",
    "\n",
    "INSTRUCCIONES:\n",
    "1. Analiza la pregunta del estudiante\n",
    "2. Decide que herramientas necesitas usar\n",
    "3. Usa las herramientas en el orden correcto\n",
    "4. Proporciona una respuesta educativa clara\n",
    "5. Si no necesitas herramientas, responde directamente\n",
    "\n",
    "Se didactico y explica el proceso paso a paso.\n",
    "\"\"\"\n",
    "\n",
    "# Crear agente ReAct (Reasoning + Acting)\n",
    "mi_agente_con_herramientas = create_react_agent(\n",
    "    llm, \n",
    "    mis_herramientas,\n",
    "    prompt=system_prompt\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Agente con herramientas creado\")\n",
    "print(\"üéØ Listo para responder preguntas y usar herramientas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ PROBANDO AGENTE CON HERRAMIENTAS\n",
      "\n",
      "‚ùì Pregunta: ¬øCuanto es 15 * 8 + 32?\n",
      "============================================================\n",
      "ü§ñ Respuesta del agente:\n",
      "Para resolver la expresion \\( 15 \\times 8 + 32 \\), seguimos estos pasos:\n",
      "\n",
      "1. Primero, multiplicamos \\( 15 \\) por \\( 8 \\):\n",
      "   \\[\n",
      "   15 \\times 8 = 120\n",
      "   \\]\n",
      "\n",
      "2. Luego, sumamos \\( 32 \\) al resultado de la multiplicacion:\n",
      "   \\[\n",
      "   120 + 32 = 152\n",
      "   \\]\n",
      "\n",
      "Por lo tanto, el resultado de \\( 15 \\times 8 + 32 \\) es \\( 152 \\).\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Funcion para probar el agente con herramientas\n",
    "def probar_agente(pregunta: str, thread_id: str = \"demo\"):\n",
    "    \"\"\"\n",
    "    Prueba el agente con una pregunta especifica.\n",
    "    \"\"\"\n",
    "    print(f\"\\n‚ùì Pregunta: {pregunta}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    entrada = {\"messages\": [HumanMessage(content=pregunta)]}\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    \n",
    "    try:\n",
    "        resultado = mi_agente_con_herramientas.invoke(entrada, config=config)\n",
    "        respuesta_final = resultado[\"messages\"][-1].content\n",
    "        \n",
    "        print(\"ü§ñ Respuesta del agente:\")\n",
    "        print(respuesta_final)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# Pruebas del agente\n",
    "print(\"üß™ PROBANDO AGENTE CON HERRAMIENTAS\")\n",
    "\n",
    "# Prueba 1: Calculo matematico\n",
    "probar_agente(\"¬øCuanto es 15 * 8 + 32?\", \"test1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùì Pregunta: ¬øQue es machine learning?\n",
      "============================================================\n",
      "ü§ñ Respuesta del agente:\n",
      "Machine learning, o aprendizaje automatico, es un subcampo de la inteligencia artificial (IA) que permite a las maquinas aprender patrones a partir de los datos sin necesidad de programacion explicita. Esto significa que, en lugar de ser programadas para realizar tareas especificas, las maquinas pueden analizar datos, identificar patrones y hacer predicciones o tomar decisiones basadas en esos patrones aprendidos. \n",
      "\n",
      "Este enfoque se utiliza en una variedad de aplicaciones, desde recomendaciones de productos hasta reconocimiento de voz y vision por computadora.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Prueba 2: Busqueda de definicion\n",
    "probar_agente(\"¬øQue es machine learning?\", \"test2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùì Pregunta: como te llamas?\n",
      "============================================================\n",
      "ü§ñ Respuesta del agente:\n",
      "Soy un asistente de inteligencia artificial y no tengo un nombre propio. Puedes llamarme simplemente \"asistente\" o \"IA\". Estoy aqui para ayudarte con tus preguntas y necesidades. ¬øEn que puedo asistirte hoy?\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Prueba 3: Multiples herramientas\n",
    "probar_agente(\"como te llamas?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üíæ 4. Persistencia y Estado - Memoria Entre Sesiones\n",
    "\n",
    "La persistencia permite que los agentes \"recuerden\" conversaciones anteriores. Esto es esencial para:\n",
    "\n",
    "- üß† **Memoria de Conversacion**: Recordar contexto anterior\n",
    "- üë§ **Personalizacion**: Adaptar respuestas al usuario\n",
    "- üîÑ **Continuidad**: Reanudar conversaciones interrumpidas\n",
    "- üêõ **Debugging**: Revisar el historial de ejecucion\n",
    "\n",
    "## Tipos de Persistencia\n",
    "\n",
    "1. **MemorySaver**: Almacenamiento temporal en memoria\n",
    "2. **SqliteSaver**: Almacenamiento permanente en base de datos\n",
    "\n",
    "## Conceptos Clave\n",
    "\n",
    "- **Checkpointer**: Guarda y restaura el estado\n",
    "- **Thread ID**: Identifica conversaciones unicas\n",
    "- **Estado Personalizado**: Informacion adicional persistente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Configurando persistencia...\n",
      "‚úÖ MemorySaver: Datos en memoria\n",
      "‚úÖ SqliteSaver: Base de datos SQLite\n",
      "\n",
      "üéØ Sistemas de persistencia listos\n"
     ]
    }
   ],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "import sqlite3\n",
    "\n",
    "print(\"üíæ Configurando persistencia...\")\n",
    "\n",
    "checkpointer_memoria = MemorySaver()\n",
    "print(\"‚úÖ MemorySaver: Datos en memoria\")\n",
    "\n",
    "conexion_sqlite = sqlite3.connect(\":memory:\", check_same_thread=False)\n",
    "checkpointer_sqlite = SqliteSaver(conexion_sqlite)\n",
    "print(\"‚úÖ SqliteSaver: Base de datos SQLite\")\n",
    "\n",
    "print(\"\\nüéØ Sistemas de persistencia listos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg[binary] in ./.venv/lib/python3.13/site-packages (3.3.2)\n",
      "Requirement already satisfied: psycopg-binary==3.3.2 in ./.venv/lib/python3.13/site-packages (from psycopg[binary]) (3.3.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"psycopg[binary]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Configurando persistencia...\n",
      "‚úÖ MemorySaver: Datos en memoria\n",
      "‚úÖ PostgresSaver: Base de datos Neon\n",
      "\n",
      "üéØ Sistemas de persistencia listos\n"
     ]
    }
   ],
   "source": [
    "# Configurar sistemas de persistencia\n",
    "print(\"üíæ Configurando persistencia...\")\n",
    "\n",
    "# 1. Persistencia en memoria (temporal)\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "checkpointer_memoria = MemorySaver()\n",
    "print(\"‚úÖ MemorySaver: Datos en memoria\")\n",
    "\n",
    "# 2. Persistencia en Postgres (Neon)\n",
    "import os\n",
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "\n",
    "database_url = os.environ.get(\"DATABASE_URL\")\n",
    "if not database_url:\n",
    "    raise RuntimeError(\"Define DATABASE_URL en .env para usar Neon/Postgres\")\n",
    "\n",
    "with PostgresSaver.from_conn_string(database_url) as checkpointer_postgres:\n",
    "    checkpointer_postgres.setup()\n",
    "    print(\"‚úÖ PostgresSaver: Base de datos Neon\")\n",
    "\n",
    "print(\"\\nüéØ Sistemas de persistencia listos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Dict, Any, Annotated\n",
    "from langchain_core.messages import BaseMessage, SystemMessage\n",
    "from langgraph.graph import add_messages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë§ Agente personalizado definido\n"
     ]
    }
   ],
   "source": [
    "# Estado personalizado para persistencia\n",
    "class EstadoPersonalizado(TypedDict):\n",
    "    \"\"\"\n",
    "    Estado que incluye informacion persistente del usuario.\n",
    "    \"\"\"\n",
    "    # Mensajes de la conversacion\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "    \n",
    "    # Informacion del usuario\n",
    "    nombre_usuario: str\n",
    "    intereses: List[str]\n",
    "    nivel_experiencia: str  # principiante, intermedio, avanzado\n",
    "    \n",
    "    # Metricas de sesion\n",
    "    numero_sesion: int\n",
    "    preguntas_realizadas: int\n",
    "    \n",
    "    # Configuracion personalizada\n",
    "    preferencias: Dict[str, Any]\n",
    "\n",
    "def agente_personalizado(state: EstadoPersonalizado) -> EstadoPersonalizado:\n",
    "    \"\"\"\n",
    "    Agente que usa informacion persistente para personalizar respuestas.\n",
    "    \"\"\"\n",
    "    # Obtener informacion del usuario\n",
    "    nombre = state.get(\"nombre_usuario\", \"Estudiante\")\n",
    "    intereses = state.get(\"intereses\", [])\n",
    "    nivel = state.get(\"nivel_experiencia\", \"principiante\")\n",
    "    sesion = state.get(\"numero_sesion\", 0) + 1\n",
    "    preguntas = state.get(\"preguntas_realizadas\", 0) + 1\n",
    "    \n",
    "    # Crear prompt personalizado\n",
    "    system_prompt = f\"\"\"\n",
    "    Eres un tutor personalizado de IA.\n",
    "    \n",
    "    INFORMACION DEL ESTUDIANTE:\n",
    "    - Nombre: {nombre}\n",
    "    - Nivel: {nivel}\n",
    "    - Intereses: {intereses if intereses else 'Aun no definidos'}\n",
    "    - Sesion actual: #{sesion}\n",
    "    - Pregunta #{preguntas} de esta conversacion\n",
    "    \n",
    "    INSTRUCCIONES:\n",
    "    1. Adapta tu respuesta al nivel del estudiante\n",
    "    2. Relaciona con sus intereses cuando sea posible\n",
    "    3. Si es la primera sesion, presentate y pregunta sobre sus intereses\n",
    "    4. Recuerda conversaciones anteriores\n",
    "    5. Se motivador y educativo\n",
    "    \"\"\"\n",
    "    \n",
    "    # Procesar mensajes\n",
    "    messages = [SystemMessage(content=system_prompt)] + state[\"messages\"]\n",
    "    respuesta = llm.invoke(messages)\n",
    "    \n",
    "    # Detectar nueva informacion del usuario\n",
    "    ultimo_mensaje = state[\"messages\"][-1].content if state[\"messages\"] else \"\"\n",
    "    nuevos_intereses = intereses.copy()\n",
    "    \n",
    "    # Buscar intereses mencionados\n",
    "    intereses_posibles = [\"machine learning\", \"deep learning\", \"nlp\", \"computer vision\", \n",
    "                         \"robotica\", \"datos\", \"programacion\", \"python\", \"javascript\"]\n",
    "    \n",
    "    for interes in intereses_posibles:\n",
    "        if interes in ultimo_mensaje.lower() and interes not in nuevos_intereses:\n",
    "            nuevos_intereses.append(interes)\n",
    "    \n",
    "    # Detectar nombre\n",
    "    nuevo_nombre = nombre\n",
    "    if \"me llamo\" in ultimo_mensaje.lower() or \"soy\" in ultimo_mensaje.lower():\n",
    "        palabras = ultimo_mensaje.split()\n",
    "        for i, palabra in enumerate(palabras):\n",
    "            if palabra.lower() in [\"llamo\", \"soy\"] and i + 1 < len(palabras):\n",
    "                nuevo_nombre = palabras[i + 1].capitalize()\n",
    "                break\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [respuesta],\n",
    "        \"nombre_usuario\": nuevo_nombre,\n",
    "        \"intereses\": nuevos_intereses,\n",
    "        \"nivel_experiencia\": nivel,\n",
    "        \"numero_sesion\": sesion,\n",
    "        \"preguntas_realizadas\": preguntas,\n",
    "        \"preferencias\": state.get(\"preferencias\", {})\n",
    "    }\n",
    "\n",
    "print(\"üë§ Agente personalizado definido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     19\u001b[39m entrada = {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [HumanMessage(content=\u001b[33m\"\u001b[39m\u001b[33mHola, soy Ana\u001b[39m\u001b[33m\"\u001b[39m)]}\n\u001b[32m     20\u001b[39m config = {\u001b[33m\"\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33musuario_1\u001b[39m\u001b[33m\"\u001b[39m}}\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43mgrafo\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentrada\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Diplomando IA/Archivos/M3/Proyecto_Final_V2/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py:3068\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3065\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3066\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3068\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3069\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Diplomando IA/Archivos/M3/Proyecto_Final_V2/.venv/lib/python3.13/site-packages/langgraph/pregel/main.py:2643\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2641\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2642\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2643\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2644\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2645\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2646\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2653\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Diplomando IA/Archivos/M3/Proyecto_Final_V2/.venv/lib/python3.13/site-packages/langgraph/pregel/_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Diplomando IA/Archivos/M3/Proyecto_Final_V2/.venv/lib/python3.13/site-packages/langgraph/pregel/_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Diplomando IA/Archivos/M3/Proyecto_Final_V2/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Diplomando IA/Archivos/M3/Proyecto_Final_V2/.venv/lib/python3.13/site-packages/langgraph/_internal/_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 53\u001b[39m, in \u001b[36magente_personalizado\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# Procesar mensajes\u001b[39;00m\n\u001b[32m     52\u001b[39m messages = [SystemMessage(content=system_prompt)] + state[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m respuesta = \u001b[43mllm\u001b[49m.invoke(messages)\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Detectar nueva informacion del usuario\u001b[39;00m\n\u001b[32m     56\u001b[39m ultimo_mensaje = state[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m][-\u001b[32m1\u001b[39m].content \u001b[38;5;28;01mif\u001b[39;00m state[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'llm' is not defined",
      "During task with name 'tutor_personal' and id '5535c531-896e-b976-498c-fb2337fe2cc4'"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "import os\n",
    "\n",
    "database_url = os.environ.get(\"DATABASE_URL\")\n",
    "if not database_url:\n",
    "    raise RuntimeError(\"Define DATABASE_URL en .env\")\n",
    "\n",
    "builder = StateGraph(EstadoPersonalizado)\n",
    "builder.add_node(\"tutor_personal\", agente_personalizado)\n",
    "builder.add_edge(START, \"tutor_personal\")\n",
    "builder.add_edge(\"tutor_personal\", END)\n",
    "\n",
    "with PostgresSaver.from_conn_string(database_url) as checkpointer:\n",
    "    checkpointer.setup()\n",
    "    grafo = builder.compile(checkpointer=checkpointer)\n",
    "\n",
    "    entrada = {\"messages\": [HumanMessage(content=\"Hola, soy Ana\")]}\n",
    "    config = {\"configurable\": {\"thread_id\": \"usuario_1\"}}\n",
    "    grafo.invoke(entrada, config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Sistema de conversacion con memoria listo\n"
     ]
    }
   ],
   "source": [
    "# Funcion para conversar con persistencia\n",
    "def conversar_con_memoria(mensaje: str, usuario_id: str = \"estudiante_1\"):\n",
    "    \"\"\"\n",
    "    Conversa con el agente que tiene memoria persistente.\n",
    "    \"\"\"\n",
    "    print(f\"\\nüë§ Tu: {mensaje}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    config = {\"configurable\": {\"thread_id\": usuario_id}}\n",
    "    entrada = {\"messages\": [HumanMessage(content=mensaje)]}\n",
    "    \n",
    "    try:\n",
    "        resultado = grafo_persistente.invoke(entrada, config=config)\n",
    "        \n",
    "        # Mostrar respuesta\n",
    "        respuesta = resultado[\"messages\"][-1].content\n",
    "        print(f\"ü§ñ Tutor: {respuesta}\")\n",
    "        \n",
    "        # Mostrar informacion persistente\n",
    "        print(f\"\\nüìä Info Persistente:\")\n",
    "        print(f\"   üë§ Usuario: {resultado.get('nombre_usuario', 'N/A')}\")\n",
    "        print(f\"   üéØ Intereses: {resultado.get('intereses', [])}\")\n",
    "        print(f\"   üìà Nivel: {resultado.get('nivel_experiencia', 'N/A')}\")\n",
    "        print(f\"   üî¢ Sesion: #{resultado.get('numero_sesion', 0)}\")\n",
    "        print(f\"   ‚ùì Preguntas: {resultado.get('preguntas_realizadas', 0)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(\"‚úÖ Sistema de conversacion con memoria listo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ DEMOSTRACION DE PERSISTENCIA\n",
      "============================================================\n",
      "\n",
      "üë§ Tu: Hola, me llamo Ana y me interesa mucho el machine learning\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'HumanMessage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m60\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Conversacion 1\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mconversar_con_memoria\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHola, me llamo Ana y me interesa mucho el machine learning\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mconversar_con_memoria\u001b[39m\u001b[34m(mensaje, usuario_id)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n\u001b[32m      9\u001b[39m config = {\u001b[33m\"\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m\"\u001b[39m: usuario_id}}\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m entrada = {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[43mHumanMessage\u001b[49m(content=mensaje)]}\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     13\u001b[39m     resultado = grafo_persistente.invoke(entrada, config=config)\n",
      "\u001b[31mNameError\u001b[39m: name 'HumanMessage' is not defined"
     ]
    }
   ],
   "source": [
    "# Demostracion de persistencia\n",
    "print(\"üß™ DEMOSTRACION DE PERSISTENCIA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Conversacion 1\n",
    "conversar_con_memoria(\"Hola, me llamo Ana y me interesa mucho el machine learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üë§ Tu: que es lo que me interesa?\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'HumanMessage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Conversacion 2 - deberia recordar el nombre\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mconversar_con_memoria\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mque es lo que me interesa?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mconversar_con_memoria\u001b[39m\u001b[34m(mensaje, usuario_id)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n\u001b[32m      9\u001b[39m config = {\u001b[33m\"\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m\"\u001b[39m: usuario_id}}\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m entrada = {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[43mHumanMessage\u001b[49m(content=mensaje)]}\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     13\u001b[39m     resultado = grafo_persistente.invoke(entrada, config=config)\n",
      "\u001b[31mNameError\u001b[39m: name 'HumanMessage' is not defined"
     ]
    }
   ],
   "source": [
    "# Conversacion 2 - deberia recordar el nombre\n",
    "conversar_con_memoria(\"que es lo que me interesa?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üë§ Tu: Tambien me interesa la programacion en Python\n",
      "--------------------------------------------------\n",
      "ü§ñ Tutor: ¬°Genial, Ana! Python es un lenguaje de programacion muy popular en el campo del machine learning y el deep learning. Es conocido por su simplicidad y legibilidad, lo que lo hace ideal para principiantes. Ademas, tiene muchas bibliotecas poderosas que facilitan el trabajo con datos y la construccion de modelos de aprendizaje automatico.\n",
      "\n",
      "Aqui hay algunas bibliotecas de Python que son especialmente utiles para el machine learning y el deep learning:\n",
      "\n",
      "1. **NumPy**: Es fundamental para el manejo de arreglos y operaciones matematicas. Te ayudara a trabajar con datos numericos de manera eficiente.\n",
      "\n",
      "2. **Pandas**: Esta biblioteca es excelente para la manipulacion y analisis de datos. Te permite trabajar con estructuras de datos como DataFrames, que son muy utiles para manejar conjuntos de datos.\n",
      "\n",
      "3. **Matplotlib y Seaborn**: Estas bibliotecas son utiles para la visualizacion de datos. Te permiten crear graficos y visualizar patrones en tus datos.\n",
      "\n",
      "4. **Scikit-learn**: Es una de las bibliotecas mas populares para machine learning en Python. Ofrece herramientas para la clasificacion, regresion y agrupamiento, entre otros.\n",
      "\n",
      "5. **TensorFlow y Keras**: Estas son bibliotecas clave para el deep learning. TensorFlow es mas compleja y poderosa, mientras que Keras es una interfaz mas sencilla que se puede usar sobre TensorFlow para construir y entrenar modelos de deep learning.\n",
      "\n",
      "Si estas comenzando con Python, te recomendaria que empieces por aprender los conceptos basicos del lenguaje y luego vayas explorando estas bibliotecas. Hay muchos recursos en linea, como tutoriales y cursos, que pueden ayudarte a avanzar.\n",
      "\n",
      "¬°No dudes en preguntar si necesitas recomendaciones de recursos o si tienes alguna duda especifica sobre Python! Estoy aqui para ayudarte en tu camino de aprendizaje.\n",
      "\n",
      "üìä Info Persistente:\n",
      "   üë§ Usuario: Ana\n",
      "   üéØ Intereses: ['machine learning', 'deep learning', 'python']\n",
      "   üìà Nivel: principiante\n",
      "   üî¢ Sesion: #3\n",
      "   ‚ùì Preguntas: 3\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Conversacion 3 - deberia recordar todo el contexto\n",
    "conversar_con_memoria(\"Tambien me interesa la programacion en Python\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
