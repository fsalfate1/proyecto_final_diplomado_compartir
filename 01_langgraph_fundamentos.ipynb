{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ LangGraph: Fundamentos y Conceptos Basicos\n",
    "\n",
    "## üìö Objetivos de Aprendizaje\n",
    "\n",
    "En este notebook aprenderas:\n",
    "- ‚úÖ Configurar LangGraph correctamente\n",
    "- ‚úÖ Entender StateGraph, nodos y aristas\n",
    "- ‚úÖ Implementar herramientas personalizadas\n",
    "- ‚úÖ Manejar persistencia y estado\n",
    "- ‚úÖ Crear tus primeros agentes multi-agente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üõ†Ô∏è 1. Configuracion del Entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "‚úÖ Todas las dependencias instaladas correctamente\n"
     ]
    }
   ],
   "source": [
    "# Instalacion de dependencias\n",
    "!pip install -q langgraph langchain_openai langchain_core langchain_community\n",
    "!pip install -q langchain-google-genai langgraph-checkpoint-sqlite\n",
    "!pip install -q python-dotenv matplotlib networkx\n",
    "\n",
    "print(\"‚úÖ Todas las dependencias instaladas correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API Key configurada desde variables de entorno\n"
     ]
    }
   ],
   "source": [
    "# Configuracion de API Keys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Cargar variables de entorno\n",
    "load_dotenv()\n",
    "\n",
    "# Para Google Colab\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
    "    print(\"‚úÖ API Key configurada desde Google Colab\")\n",
    "except:\n",
    "    \n",
    "    if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "        print(\"‚ö†Ô∏è Configura tu OPENAI_API_KEY\")\n",
    "        # Descomenta la siguiente linea y agrega tu API key\n",
    "        # os.environ[\"OPENAI_API_KEY\"] = \"tu-api-key-aqui\"\n",
    "    else:\n",
    "        print(\"‚úÖ API Key configurada desde variables de entorno\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Importaciones completadas\n"
     ]
    }
   ],
   "source": [
    "# Importaciones basicas\n",
    "import json\n",
    "import time\n",
    "import sqlite3\n",
    "from typing import Literal, List, Dict, Any, Optional, TypedDict, Annotated\n",
    "from datetime import datetime\n",
    "\n",
    "# LangChain y LangGraph\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, BaseMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# LangGraph core\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END, add_messages\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "print(\"‚úÖ Importaciones completadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ¬°Configuracion exitosa! Si necesitas ayuda con algo mas o tienes alguna pregunta, no dudes en decirmelo.\n"
     ]
    }
   ],
   "source": [
    "# Configurar modelo principal\n",
    "try:\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-4o-mini\",  # Modelo mas economico para aprendizaje\n",
    "        temperature=0.1,\n",
    "        max_tokens=1000\n",
    "    )\n",
    "    \n",
    "    # Prueba de configuracion\n",
    "    test_response = llm.invoke([HumanMessage(content=\"Di: 'Configuracion exitosa'\")])  \n",
    "    print(f\"‚úÖ {test_response.content}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    print(\"Verifica tu API key y conexion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üß† 2. Conceptos Fundamentales de LangGraph\n",
    "\n",
    "## ¬øQue es LangGraph?\n",
    "\n",
    "LangGraph es una biblioteca para construir **sistemas multi-agente** usando grafos. Los conceptos clave son:\n",
    "\n",
    "- **üîó StateGraph**: El grafo que define el flujo de ejecucion\n",
    "- **üì¶ Estado**: Informacion que fluye entre nodos (como `MessagesState`)\n",
    "- **üéØ Nodos**: Funciones que procesan el estado\n",
    "- **‚û°Ô∏è Aristas**: Conexiones que definen el flujo\n",
    "- **üé≠ Agentes**: Funciones inteligentes que pueden usar herramientas\n",
    "\n",
    "## Diagrama Conceptual\n",
    "\n",
    "```\n",
    "[Estado Inicial] ‚Üí [Nodo 1] ‚Üí [Nodo 2] ‚Üí [Estado Final]\n",
    "                      ‚Üì         ‚Üì\n",
    "                 [Herramientas] [Decisiones]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Funcion de agente definida\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo 1: Tu primer grafo simple\n",
    "def mi_primer_agente(state: MessagesState) -> MessagesState:\n",
    "    \"\"\"\n",
    "    Un agente simple que procesa mensajes.\n",
    "    \n",
    "    Args:\n",
    "        state: Estado actual con mensajes\n",
    "        \n",
    "    Returns:\n",
    "        Estado actualizado con nueva respuesta\n",
    "    \"\"\"\n",
    "    print(\"ü§ñ Mi primer agente esta trabajando...\")\n",
    "    \n",
    "    # Crear prompt del sistema\n",
    "    system_prompt = \"Eres un asistente educativo que explica conceptos de IA de manera simple.\"\n",
    "\n",
    "    print(state)\n",
    "    \n",
    "    # Construir mensajes para el LLM\n",
    "    messages = [SystemMessage(content=system_prompt)] + state[\"messages\"]\n",
    "    \n",
    "    # Obtener respuesta\n",
    "    respuesta = llm.invoke(messages)\n",
    "    \n",
    "    print(f\"‚úÖ Agente completo su trabajo\")\n",
    "    \n",
    "    # Retornar estado actualizado\n",
    "    return {\"messages\": [respuesta]}\n",
    "\n",
    "print(\"‚úÖ Funcion de agente definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è Construyendo mi primer grafo...\n",
      "‚úÖ ¬°Tu primer grafo esta listo!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construir tu primer grafo\n",
    "from IPython.display import Image\n",
    "\n",
    "print(\"üèóÔ∏è Construyendo mi primer grafo...\")\n",
    "\n",
    "# 1. Crear el builder del grafo\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# 2. Anadir nodo\n",
    "builder.add_node(\"mi_agente\", mi_primer_agente)\n",
    "\n",
    "# 3. Definir flujo: START ‚Üí mi_agente ‚Üí END\n",
    "builder.add_edge(START, \"mi_agente\")\n",
    "builder.add_edge(\"mi_agente\", END)\n",
    "\n",
    "# 4. Compilar grafo\n",
    "mi_primer_grafo = builder.compile()\n",
    "\n",
    "print(\"‚úÖ ¬°Tu primer grafo esta listo!\")\n",
    "\n",
    "Image(mi_primer_grafo.get_graph().draw_mermaid_png())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ PROBANDO MI PRIMER GRAFO\n",
      "========================================\n",
      "‚ùì Pregunta: ¬øQue es un grafo en LangGraph?\n",
      "\n",
      "üîÑ Ejecutando grafo...\n",
      "ü§ñ Mi primer agente esta trabajando...\n",
      "{'messages': [HumanMessage(content='¬øQue es un grafo en LangGraph?', additional_kwargs={}, response_metadata={}, id='ff662f6a-7f86-43a9-88b1-7696c2f7e8ad')]}\n",
      "‚úÖ Agente completo su trabajo\n",
      "\n",
      "ü§ñ Respuesta:\n",
      "[HumanMessage(content='¬øQue es un grafo en LangGraph?', additional_kwargs={}, response_metadata={}, id='ff662f6a-7f86-43a9-88b1-7696c2f7e8ad'), AIMessage(content='Un grafo en LangGraph es una estructura que se utiliza para representar relaciones entre diferentes elementos, como palabras, frases o conceptos. En terminos simples, un grafo esta compuesto por nodos (que representan los elementos) y aristas (que representan las conexiones o relaciones entre esos elementos).\\n\\nEn el contexto de LangGraph, los grafos pueden ayudar a modelar y entender como se relacionan diferentes partes del lenguaje, lo que puede ser util para tareas como el procesamiento del lenguaje natural, la generacion de texto o la comprension de significados. Por ejemplo, un grafo podria mostrar como una palabra se relaciona con sinonimos, antonimos o palabras que suelen aparecer juntas en un texto.\\n\\nAsi que, en resumen, un grafo en LangGraph es una forma de visualizar y analizar las conexiones entre diferentes elementos del lenguaje.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 168, 'prompt_tokens': 35, 'total_tokens': 203, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-C64WQFlVFSTKZhbqPj4500bKFoMvD', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c9107cd5-c647-4c0e-a91e-8238bb2c51de-0', usage_metadata={'input_tokens': 35, 'output_tokens': 168, 'total_tokens': 203, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "\n",
      "========================================\n",
      "üéâ ¬°Felicitaciones! Has ejecutado tu primer grafo LangGraph\n"
     ]
    }
   ],
   "source": [
    "# Probar tu primer grafo\n",
    "print(\"üß™ PROBANDO MI PRIMER GRAFO\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Entrada del usuario\n",
    "entrada = {\n",
    "    \"messages\": [HumanMessage(content=\"¬øQue es un grafo en LangGraph?\")]\n",
    "}\n",
    "\n",
    "print(f\"‚ùì Pregunta: {entrada['messages'][0].content}\")\n",
    "print(\"\\nüîÑ Ejecutando grafo...\")\n",
    "\n",
    "# Ejecutar\n",
    "resultado = mi_primer_grafo.invoke(entrada)\n",
    "\n",
    "print(f\"\\nü§ñ Respuesta:\")\n",
    "print(resultado[\"messages\"])\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"üéâ ¬°Felicitaciones! Has ejecutado tu primer grafo LangGraph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üõ†Ô∏è 3. Herramientas (@tool) - Extendiendo Capacidades\n",
    "\n",
    "Las herramientas permiten que los agentes interactuen con el mundo exterior:\n",
    "- üåê APIs web\n",
    "- üóÑÔ∏è Bases de datos  \n",
    "- üßÆ Calculadoras\n",
    "- üìä Analisis de datos\n",
    "- üìß Envio de emails\n",
    "\n",
    "## ¬øComo Funcionan?\n",
    "\n",
    "1. **Definir**: Usar decorator `@tool`\n",
    "2. **Describir**: Docstring clara para que el agente entienda cuando usarla\n",
    "3. **Integrar**: Pasar herramientas al agente\n",
    "4. **Ejecutar**: El agente decide cuando y como usar cada herramienta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõ†Ô∏è Herramientas creadas:\n",
      "  ‚úÖ calculadora_simple\n",
      "  ‚úÖ obtener_fecha_actual\n",
      "  ‚úÖ buscar_definicion\n",
      "  ‚úÖ generar_numero_aleatorio\n",
      "\n",
      "üìä Total: 4 herramientas disponibles\n"
     ]
    }
   ],
   "source": [
    "# Crear herramientas basicas\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "@tool\n",
    "def calculadora_simple(expresion: str) -> str:\n",
    "    \"\"\"\n",
    "    Realiza calculos matematicos basicos.\n",
    "    \n",
    "    Args:\n",
    "        expresion: Expresion matematica (ej: \"2 + 3 * 4\")\n",
    "        \n",
    "    Returns:\n",
    "        Resultado del calculo\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Solo permitir operaciones seguras\n",
    "        allowed_chars = set(\"0123456789+-*/(). \")\n",
    "        if not all(c in allowed_chars for c in expresion):\n",
    "            return \"Error: Solo numeros y operadores basicos permitidos\"\n",
    "        \n",
    "        resultado = eval(expresion)\n",
    "        return f\"El resultado de '{expresion}' es: {resultado}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error al calcular: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def obtener_fecha_actual() -> str:\n",
    "    \"\"\"\n",
    "    Obtiene la fecha y hora actual.\n",
    "    \n",
    "    Returns:\n",
    "        Fecha y hora actuales\n",
    "    \"\"\"\n",
    "    ahora = datetime.now()\n",
    "    return f\"Hoy es {ahora.strftime('%Y-%m-%d')} y son las {ahora.strftime('%H:%M:%S')}\"\n",
    "\n",
    "@tool\n",
    "def buscar_definicion(termino: str) -> str:\n",
    "    \"\"\"\n",
    "    Busca la definicion de terminos tecnicos de IA.\n",
    "    \n",
    "    Args:\n",
    "        termino: Termino a definir\n",
    "        \n",
    "    Returns:\n",
    "        Definicion del termino\n",
    "    \"\"\"\n",
    "    definiciones = {\n",
    "        \"machine learning\": \"Subcampo de la IA que permite a las maquinas aprender patrones de los datos sin programacion explicita.\",\n",
    "        \"deep learning\": \"Tecnica de ML que usa redes neuronales profundas para aprender representaciones complejas.\",\n",
    "        \"llm\": \"Large Language Model - Modelo de lenguaje grande entrenado con enormes cantidades de texto.\",\n",
    "        \"grafo\": \"Estructura de datos que consiste en nodos conectados por aristas.\",\n",
    "        \"agente\": \"Sistema de IA que puede percibir su entorno y tomar acciones para lograr objetivos.\"\n",
    "    }\n",
    "    \n",
    "    termino_lower = termino.lower()\n",
    "    if termino_lower in definiciones:\n",
    "        return f\"üìö {termino}: {definiciones[termino_lower]}\"\n",
    "    else:\n",
    "        return f\"ü§î No encontre definicion para '{termino}'. Terminos disponibles: {', '.join(definiciones.keys())}\"\n",
    "\n",
    "@tool  \n",
    "def generar_numero_aleatorio(minimo: int = 1, maximo: int = 100) -> str:\n",
    "    \"\"\"\n",
    "    Genera un numero aleatorio en un rango.\n",
    "    \n",
    "    Args:\n",
    "        minimo: Valor minimo (default: 1)\n",
    "        maximo: Valor maximo (default: 100)\n",
    "        \n",
    "    Returns:\n",
    "        Numero aleatorio generado\n",
    "    \"\"\"\n",
    "    numero = random.randint(minimo, maximo)\n",
    "    return f\"üé≤ Numero aleatorio entre {minimo} y {maximo}: {numero}\"\n",
    "\n",
    "# Lista de herramientas\n",
    "mis_herramientas = [\n",
    "    calculadora_simple,\n",
    "    obtener_fecha_actual,\n",
    "    buscar_definicion,\n",
    "    generar_numero_aleatorio\n",
    "]\n",
    "\n",
    "print(\"üõ†Ô∏è Herramientas creadas:\")\n",
    "for herramienta in mis_herramientas:\n",
    "    print(f\"  ‚úÖ {herramienta.name}\")\n",
    "print(f\"\\nüìä Total: {len(mis_herramientas)} herramientas disponibles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Creando agente con herramientas...\n",
      "‚úÖ Agente con herramientas creado\n",
      "üéØ Listo para responder preguntas y usar herramientas\n"
     ]
    }
   ],
   "source": [
    "# Crear agente con herramientas\n",
    "print(\"ü§ñ Creando agente con herramientas...\")\n",
    "\n",
    "# Prompt personalizado para el agente\n",
    "system_prompt = \"\"\"\n",
    "Eres un tutor de IA inteligente con acceso a herramientas especializadas.\n",
    "\n",
    "HERRAMIENTAS DISPONIBLES:\n",
    "- calculadora_simple: Para hacer calculos matematicos\n",
    "- obtener_fecha_actual: Para saber la fecha y hora\n",
    "- buscar_definicion: Para definir terminos tecnicos\n",
    "- generar_numero_aleatorio: Para generar numeros aleatorios\n",
    "\n",
    "INSTRUCCIONES:\n",
    "1. Analiza la pregunta del estudiante\n",
    "2. Decide que herramientas necesitas usar\n",
    "3. Usa las herramientas en el orden correcto\n",
    "4. Proporciona una respuesta educativa clara\n",
    "5. Si no necesitas herramientas, responde directamente\n",
    "\n",
    "Se didactico y explica el proceso paso a paso.\n",
    "\"\"\"\n",
    "\n",
    "# Crear agente ReAct (Reasoning + Acting)\n",
    "mi_agente_con_herramientas = create_react_agent(\n",
    "    llm, \n",
    "    mis_herramientas,\n",
    "    prompt=system_prompt\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Agente con herramientas creado\")\n",
    "print(\"üéØ Listo para responder preguntas y usar herramientas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ PROBANDO AGENTE CON HERRAMIENTAS\n",
      "\n",
      "‚ùì Pregunta: ¬øCuanto es 15 * 8 + 32?\n",
      "============================================================\n",
      "ü§ñ Respuesta del agente:\n",
      "Para resolver la expresion \\( 15 \\times 8 + 32 \\), seguimos estos pasos:\n",
      "\n",
      "1. Primero, multiplicamos \\( 15 \\) por \\( 8 \\):\n",
      "   \\[\n",
      "   15 \\times 8 = 120\n",
      "   \\]\n",
      "\n",
      "2. Luego, sumamos \\( 32 \\) al resultado de la multiplicacion:\n",
      "   \\[\n",
      "   120 + 32 = 152\n",
      "   \\]\n",
      "\n",
      "Por lo tanto, el resultado de \\( 15 \\times 8 + 32 \\) es \\( 152 \\).\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Funcion para probar el agente con herramientas\n",
    "def probar_agente(pregunta: str, thread_id: str = \"demo\"):\n",
    "    \"\"\"\n",
    "    Prueba el agente con una pregunta especifica.\n",
    "    \"\"\"\n",
    "    print(f\"\\n‚ùì Pregunta: {pregunta}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    entrada = {\"messages\": [HumanMessage(content=pregunta)]}\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    \n",
    "    try:\n",
    "        resultado = mi_agente_con_herramientas.invoke(entrada, config=config)\n",
    "        respuesta_final = resultado[\"messages\"][-1].content\n",
    "        \n",
    "        print(\"ü§ñ Respuesta del agente:\")\n",
    "        print(respuesta_final)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# Pruebas del agente\n",
    "print(\"üß™ PROBANDO AGENTE CON HERRAMIENTAS\")\n",
    "\n",
    "# Prueba 1: Calculo matematico\n",
    "probar_agente(\"¬øCuanto es 15 * 8 + 32?\", \"test1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùì Pregunta: ¬øQue es machine learning?\n",
      "============================================================\n",
      "ü§ñ Respuesta del agente:\n",
      "Machine learning, o aprendizaje automatico, es un subcampo de la inteligencia artificial (IA) que permite a las maquinas aprender patrones a partir de los datos sin necesidad de programacion explicita. Esto significa que, en lugar de ser programadas para realizar tareas especificas, las maquinas pueden analizar datos, identificar patrones y hacer predicciones o tomar decisiones basadas en esos patrones aprendidos. \n",
      "\n",
      "Este enfoque se utiliza en una variedad de aplicaciones, desde recomendaciones de productos hasta reconocimiento de voz y vision por computadora.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Prueba 2: Busqueda de definicion\n",
    "probar_agente(\"¬øQue es machine learning?\", \"test2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ùì Pregunta: como te llamas?\n",
      "============================================================\n",
      "ü§ñ Respuesta del agente:\n",
      "Soy un asistente de inteligencia artificial y no tengo un nombre propio. Puedes llamarme simplemente \"asistente\" o \"IA\". Estoy aqui para ayudarte con tus preguntas y necesidades. ¬øEn que puedo asistirte hoy?\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Prueba 3: Multiples herramientas\n",
    "probar_agente(\"como te llamas?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üíæ 4. Persistencia y Estado - Memoria Entre Sesiones\n",
    "\n",
    "La persistencia permite que los agentes \"recuerden\" conversaciones anteriores. Esto es esencial para:\n",
    "\n",
    "- üß† **Memoria de Conversacion**: Recordar contexto anterior\n",
    "- üë§ **Personalizacion**: Adaptar respuestas al usuario\n",
    "- üîÑ **Continuidad**: Reanudar conversaciones interrumpidas\n",
    "- üêõ **Debugging**: Revisar el historial de ejecucion\n",
    "\n",
    "## Tipos de Persistencia\n",
    "\n",
    "1. **MemorySaver**: Almacenamiento temporal en memoria\n",
    "2. **SqliteSaver**: Almacenamiento permanente en base de datos\n",
    "\n",
    "## Conceptos Clave\n",
    "\n",
    "- **Checkpointer**: Guarda y restaura el estado\n",
    "- **Thread ID**: Identifica conversaciones unicas\n",
    "- **Estado Personalizado**: Informacion adicional persistente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Configurando persistencia...\n",
      "‚úÖ MemorySaver: Datos en memoria\n",
      "‚úÖ SqliteSaver: Base de datos SQLite\n",
      "\n",
      "üéØ Sistemas de persistencia listos\n"
     ]
    }
   ],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "import sqlite3\n",
    "\n",
    "print(\"üíæ Configurando persistencia...\")\n",
    "\n",
    "checkpointer_memoria = MemorySaver()\n",
    "print(\"‚úÖ MemorySaver: Datos en memoria\")\n",
    "\n",
    "conexion_sqlite = sqlite3.connect(\":memory:\", check_same_thread=False)\n",
    "checkpointer_sqlite = SqliteSaver(conexion_sqlite)\n",
    "print(\"‚úÖ SqliteSaver: Base de datos SQLite\")\n",
    "\n",
    "print(\"\\nüéØ Sistemas de persistencia listos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Configurando persistencia...\n",
      "‚úÖ MemorySaver: Datos en memoria\n",
      "‚úÖ SqliteSaver: Base de datos SQLite\n",
      "\n",
      "üéØ Sistemas de persistencia listos\n"
     ]
    }
   ],
   "source": [
    "# Configurar sistemas de persistencia\n",
    "print(\"üíæ Configurando persistencia...\")\n",
    "\n",
    "# 1. Persistencia en memoria (temporal)\n",
    "checkpointer_memoria = MemorySaver()\n",
    "print(\"‚úÖ MemorySaver: Datos en memoria\")\n",
    "\n",
    "# 2. Persistencia en SQLite (permanente)\n",
    "conexion_sqlite = sqlite3.connect(\":memory:\", check_same_thread=False)\n",
    "checkpointer_sqlite = SqliteSaver(conexion_sqlite)\n",
    "print(\"‚úÖ SqliteSaver: Base de datos SQLite\")\n",
    "\n",
    "print(\"\\nüéØ Sistemas de persistencia listos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë§ Agente personalizado definido\n"
     ]
    }
   ],
   "source": [
    "# Estado personalizado para persistencia\n",
    "class EstadoPersonalizado(TypedDict):\n",
    "    \"\"\"\n",
    "    Estado que incluye informacion persistente del usuario.\n",
    "    \"\"\"\n",
    "    # Mensajes de la conversacion\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "    \n",
    "    # Informacion del usuario\n",
    "    nombre_usuario: str\n",
    "    intereses: List[str]\n",
    "    nivel_experiencia: str  # principiante, intermedio, avanzado\n",
    "    \n",
    "    # Metricas de sesion\n",
    "    numero_sesion: int\n",
    "    preguntas_realizadas: int\n",
    "    \n",
    "    # Configuracion personalizada\n",
    "    preferencias: Dict[str, Any]\n",
    "\n",
    "def agente_personalizado(state: EstadoPersonalizado) -> EstadoPersonalizado:\n",
    "    \"\"\"\n",
    "    Agente que usa informacion persistente para personalizar respuestas.\n",
    "    \"\"\"\n",
    "    # Obtener informacion del usuario\n",
    "    nombre = state.get(\"nombre_usuario\", \"Estudiante\")\n",
    "    intereses = state.get(\"intereses\", [])\n",
    "    nivel = state.get(\"nivel_experiencia\", \"principiante\")\n",
    "    sesion = state.get(\"numero_sesion\", 0) + 1\n",
    "    preguntas = state.get(\"preguntas_realizadas\", 0) + 1\n",
    "    \n",
    "    # Crear prompt personalizado\n",
    "    system_prompt = f\"\"\"\n",
    "    Eres un tutor personalizado de IA.\n",
    "    \n",
    "    INFORMACION DEL ESTUDIANTE:\n",
    "    - Nombre: {nombre}\n",
    "    - Nivel: {nivel}\n",
    "    - Intereses: {intereses if intereses else 'Aun no definidos'}\n",
    "    - Sesion actual: #{sesion}\n",
    "    - Pregunta #{preguntas} de esta conversacion\n",
    "    \n",
    "    INSTRUCCIONES:\n",
    "    1. Adapta tu respuesta al nivel del estudiante\n",
    "    2. Relaciona con sus intereses cuando sea posible\n",
    "    3. Si es la primera sesion, presentate y pregunta sobre sus intereses\n",
    "    4. Recuerda conversaciones anteriores\n",
    "    5. Se motivador y educativo\n",
    "    \"\"\"\n",
    "    \n",
    "    # Procesar mensajes\n",
    "    messages = [SystemMessage(content=system_prompt)] + state[\"messages\"]\n",
    "    respuesta = llm.invoke(messages)\n",
    "    \n",
    "    # Detectar nueva informacion del usuario\n",
    "    ultimo_mensaje = state[\"messages\"][-1].content if state[\"messages\"] else \"\"\n",
    "    nuevos_intereses = intereses.copy()\n",
    "    \n",
    "    # Buscar intereses mencionados\n",
    "    intereses_posibles = [\"machine learning\", \"deep learning\", \"nlp\", \"computer vision\", \n",
    "                         \"robotica\", \"datos\", \"programacion\", \"python\", \"javascript\"]\n",
    "    \n",
    "    for interes in intereses_posibles:\n",
    "        if interes in ultimo_mensaje.lower() and interes not in nuevos_intereses:\n",
    "            nuevos_intereses.append(interes)\n",
    "    \n",
    "    # Detectar nombre\n",
    "    nuevo_nombre = nombre\n",
    "    if \"me llamo\" in ultimo_mensaje.lower() or \"soy\" in ultimo_mensaje.lower():\n",
    "        palabras = ultimo_mensaje.split()\n",
    "        for i, palabra in enumerate(palabras):\n",
    "            if palabra.lower() in [\"llamo\", \"soy\"] and i + 1 < len(palabras):\n",
    "                nuevo_nombre = palabras[i + 1].capitalize()\n",
    "                break\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [respuesta],\n",
    "        \"nombre_usuario\": nuevo_nombre,\n",
    "        \"intereses\": nuevos_intereses,\n",
    "        \"nivel_experiencia\": nivel,\n",
    "        \"numero_sesion\": sesion,\n",
    "        \"preguntas_realizadas\": preguntas,\n",
    "        \"preferencias\": state.get(\"preferencias\", {})\n",
    "    }\n",
    "\n",
    "print(\"üë§ Agente personalizado definido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è Creando grafo con persistencia...\n",
      "‚úÖ Grafo con persistencia creado\n",
      "üß† El agente recordara conversaciones anteriores\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJQAAADqCAIAAADLdvsyAAAAAXNSR0IArs4c6QAAF7dJREFUeJztnXdcU+fewJ/kZEBCwgwJICobQWWF4RaxUsttrUIdONt6r2i119ZR7VCvo7ZWrb7Wive2t2/7urCuttBarQtcFasgQ1AEUZCRBMgk+9w/0pdLNYCleU540uf74Y/knCfP8zvnyxnPecahkSQJMGhCt3cAmN6D5SEMlocwWB7CYHkIg+UhDMO+xbdJDHKZQaMwqhUmo57s+/UWGp3GYNK4fILDZ7h5MV29mPYMxi77q+mBrrpEVV2icvNmmYwkl8/g8AmWEx2YqY/ld0IHeq1ZozCpFUY6nSaXGQIHc4OGunj7s6mPhWp5LY36y3kyZw7h5s0MHMx1F7KoLN3mtDTqa0rVrRK9rt08PM2T4s2hVN7lXNn9cvWwNM+ASC5lhVJDdan6Sq40cIjLsDRPygqlTt6hbQ/F492Do1yoKc4u3L2punm+deob/tQUR8ndphnsXl6VMt3bsc0BAEJiXMZmeH+64h5FF28SPp8su2swUFBOX0HXbvp0RRUFBUE/beZsezhumregnx1uxuxI0wPdhWPNU5fCPX/ClXclTybwcwqOdrTbk6fhzk1VS4M+6TkPeEVAvObJGvQ1Zeo/pzkAQGiMy71bytZmA7wiIMq7/J10xPNe8PLv+wx/3uvSd1J4+cOS13Bfy3VlDBjEgZQ/EgREcp25RON9LaT8Ycm7V6zyoPzpyfjx4+vr63/vr3JyctauXQsnIuDuzawuUUPKHJa8mjL1QGofo9TV1bW1tfXih2VlZRDC+ZWASG5NmQpS5lBaFVqbDJ4ilpsAyhN3kiQPHDiQl5f34MGDgICAxMTEhQsXFhYWLl68GAAwadKkcePGbdmy5d69e0eOHLl27VpjY2NAQEB6evrkyZMBAJWVlTNnztyxY8eGDRsEAgGbzS4uLgYA5OXlHTp0KDg42LbRugtZrl6sNonRTQBhV8OoPNaUqr77Vz2MnC3mxo8fn5ubK5VKjxw5Mm7cuC+//JIkyYKCgri4uLq6OkuyBQsWTJ48+dq1a4WFhYcPH46Li7ty5QpJktXV1XFxcdOnT9+3b19ZWRlJknPnzl2zZg2kaEmS/GZv/f3bahg5Qzny1EoTlw+rpfDGjRuRkZFpaWkAgPT09ISEBK3Wyh3Bhx9+qNFofHx8AABisfjEiROXL19OSkoiCAIAMGbMmJkzZ0KK8DG4fIZGYYSRMxx5CiMHmryoqKhdu3atX78+NjZ2zJgx/v7Wn2KYzeb9+/dfvnz5wYMHliUBAQEdawcNGgQpvCfh8Am1wgQjZ1i7mE6nQcp5xowZHA4nPz9/3bp1DAYjNTV1yZIlXl6/qVCaTKYlS5aQJPn666/Hx8dzudx58+Z1TsBmU/e4jiBg7Qoo8rg8RvNDWJUbgiCmTJkyZcqUe/fuXbt2be/evWq1euvWrZ3TlJeXV1RU7NmzJz4+3rJEqVRCiqdHlK1GnwAnGDlDkcfhE2ollBMFSZJ5eXkRERGBgYFBQUFBQUFyuTwvL++xZJY6g0AgsHytqqqqra2l8lTZGY3CCOkOAEo9j+/BZDChnCtoNFpubu7KlSsLCgoUCsXFixfPnz8fFRUFABg4cCAA4KeffiorKwsKCqLRaPv371epVDU1NVu3bk1ISGhoaLCap7+/f3l5+fXr11tbW2HEzGDR+e5w+inBuIUlSfJ/19fIZVAa8RoaGpYtWxYXFxcXF5eampqdna1SqSyr1q1bZ6n2kSR58uTJjIyMuLi4yZMnl5aWnj59Oi4ubsaMGbW1tR3VBgs3btxIT0+Pj48vLCy0ebRtEv1Xm+7bPFsLsJqE8o9J3ASsoaNcYWSOEEUX2lRtxpGToDygh/V4LGioi6xRDylzhGht0gcOgdX5A1ZVwS/Y+dqPLfVV7X7BzlYT1NXVzZo1y+oqgiBMJuv3OxkZGZbHYDBYvnz59evXra7y8PBoaWmxumr9+vWjR4+2uurhnXa5zOAbCOVWE25LevddAYxGY3Nzs9VVSqWSx+NZXcXlcl1dYZ2KpVKpXm/9bKHVap2crDvw8PDoahXsLiBwu0EUnJD2D+P8OVv17pdp6qo0kK52FuB2/Rv1oteFYxK5FGJXgL5Ja7Ph4rcSqOao6LeZubL/gS0PYJfS1zi4pTZz5QDoxUCqgnTGaCD3rKyCVO3ra7RJ9J+uqDIZqSiLou7uBj15cEvt2Azv/uGOfP2rva3JPy7JXNGfgPOA6TEoHWiSf0wiqdcNf97LZyCsu2d70VCtvZQrFfo7jZpMXYc5qod4WTbSux/b05cdEMnl8AgqS7c5aoXpfpla2qCT2uOf0j6DKx9UtN+7pawuVfuHcEjw6+BKthO9zw+MBTQaTac1WQZXAkCrr9IERHKDonj9w6w/i4AbjH1HEjc/0MllBrXCqFYYjTobx1JZWUmn00NCQmyYJ41OY7AAl8/g8hmuXky7DIjtwM5j0r37s737w9r+iuyjNAZj7EvDIeVvd/BsEAiD5SEMlocwWB7CYHkIg+UhDJaHMFgewmB5CIPlIQyWhzBYHsJgeQiD5SEMlocwWB7CYHkIg+UhDJaHMFgewmB5CIPlIQyWhzCOLI9Go1lmGnNUHFkeSZJdjW13DBxZnsOD5SEMlocwWB7CYHkIg+UhDJaHMFgewmB5CIPlIQyWhzBYHsJgeQiD5SEMlocwdp4BCQbJyclyufyxhW5ubmfPnrVTRLBwwCNvxIgR9N9Co9FGjRpl77hsjwPKmz17tlAo7LxEJBJR9sI1KnFAeWFhYdHR0Z2XiMXi0NBQ+0UECweUZzn4RCKR5bNQKMzMzLR3RFBwTHnh4eGWt0MBAGJjY8PCwuwdERQcUx4AYM6cOSKRSCgUzpkzx96xwKLn+TYba3TSBp1GCeWtpzARiIOmAwBaqz2vVVt/k0yfhctjePqyRQN7mIm0u3qeQUd+k11Po9NcBSy2syP3Xu1raDUmhUwPSHLSAj8Gq8uJ4ruUZ9CZv9nbEJPs6d3f0WZiR4WmWm3xedmkLN+u/HV5zTux51HsOGzOnggHOEWN9fxmb31XCazLe3RPy2DTBf7YnJ0RDnCi0WgNNdbfnmxdnqRe5+bJghwY5qlw9WJJ6nVWV1mXp1Ea2Rx8h9InYHMJTRevvnbYet6fASwPYbA8hMHyEAbLQxgsD2GwPITB8hAGy0MYLA9hsDyEwfIQBsujlKPHDo2fkGir3Gwm79jxnM0fru0xWXV11fTMv9iq0D85NpNXUVn2NMluV5TaqkSMbeQt+furp09/f+pUXnKKuLq6av+BLyamjexY+6ihPjlFfPXqxc8+371128ampsbkFPHRY4cAABqNZuP772ZMfTZ14vAFWbO++faI5SdHjh7ImPrsxUvnx09I/HTPx90UXX67NDlFnF9w9pX505JTxBlTn92TvaNjrVQqWb9h9bQZaS9OGf/+B2vqH9V1lf/VqxeXvvm3iWkj58xL/2DLOplMaknZVYRVVXeSU8S3K8reXbMsOUU8bUZa9t6dHR2Cjh3PWfnW4udfGJv+UurGTe80ND6yyX5+DNvI27Xz80GDBk+YkHbuzPXAwOCuks1/9bXp0+YIhaJzZ66nT5kOAFj19usNDfWbNn6cczBvxIixO3Z+cOduBQCAyWS1t2sO5Xz19uoNL7yQ0U3RbBYbALB//7/f37jj5PeXFma9cez4oR9/zAUAGI3GN5dnlZQWLV/23hefH+bx+AsXzrbsx8fyv3O34p333hTHJX35xdFFWW/cvVuxdftGS/5dRchisQAAW7dteGb8c6dOXln11j9yDv/f+Qs/AQCKin7Z9clHQ4bErF+/ddVb/2iWNL2/+T2b7OfHsOcNy9WfL5WUFL21Ym1Y6CA3N/c5s+dHRAzZt+9zAABBEBqN5tVXFo1LntDPz7+bTGg0GgBg9OgUkciHzWanjEuNi0s8c/YkAKD41o2HD2tXr1ofL05yd/d4beGbLi68o0cPPpl/aUkRm82emfmyt7cwKWnk9q3ZU1+a1X2EdDodADB2zDNjRqcwmcyYaLFQKLpz5zYAYMiQ6H9/lpM5Y15MtDhenDT1pVmlpcUqlcrmO9CeL7mvqanicDj9+w/sWBIWOujylfxOXyOeMqugwJCOz35+/pcunQcAlJQUMZnM2Jh4y3I6nT40Krak5OaT+Q8eEt3e3r7q7b8niIclDRvl59svJlr8NBGGhg7q+OziwlOplJb/jPr6h5/s3lp5p1ytVlvWtrW1uLi4/J7d0zP2lCeTSZ2dOZ2XODtzNP+/tR2npqfBycn5v5/ZTmqVCgCgUikNBkNyirhzSk9PryfzDw0J3/z+zvz8M9n/3PnJp9vixUnz5i6IiBjSY4SW4+8x8gvOrl23cs7s+a8tWhYYGHz16sXV7yx9yg35XVAhz9zFdLNcLlejUXdeotGoPb0EvSjC8i9vQavTOjk7Wzw5Oztv2vib+x0GYX2TkxJHJCWOeHle1o0b174+un/1O0uPHTnVuwjz8o4PHRrz8rysX2NT2/6EaQHKNY/FYun1eqPx1+ENtbU1VpOFhUa0t7dXV1d1LCkvLwkYGNSLEouKf+n4fPduhSWTwMCQ9vZ2kcg3Jlps+fP2FgUHWxkxdLPoeuH1qwAAgcA7NfUvixa+qVDImyVNvYtQoZB7ef5XcEEBrOHUNpPn5+dfWVl+s+h6W1trZGSU2Ww+/dP3AIDGxoZDh7/qSNavX3+ZTHrp0oW6ugcJCcN9ffy2bt9YUVne0iL712ef3LlbkZHem7F0hdevWPb+hfwzJSVFKeOeBQAkJgxPSBj+0Ufrm5oa29pajx3Pycqa9eOp3Cd/fuvWzTVrl+fmHZfL28pvlx4/nuPtLfQWCHsXYVBQ6C83rhUX3zAajYe/3meZpLypubEX29U9NpP3fNoUkiSXr1hUc/9exKDBC7OW7tnzcXKKeNPmd195eWFHsqTEkUMGR7+7ZtnZc6cYDMbGDdt5LrxFr82dOXtSUfEvmzZsj4gY0ovSM6fPy967IzlFvGHj2xnpmampvz7E2bxpx+jRKes3rp6c/sw33349ceKkFye99OTPZ0yfm/bc5F2ffPTilPHLlmfxePzt2/YSBNG7CP86f3FcbMLb7y6d8OwwmUz61sp1IcFhy1csyrf1IWh9oMmVPBlJ0oeMcrdtYTCorq569a/Td378r6FDY+wdCxSK81sYDJA00ePJVfjBNMLYs6rwlJSV3Vq1+vWu1m5+/3+oDacPgYC8yMih//znga7W+oh8z525Tm1EfQUE5FkM2TuEvgi+5iEMlocwWB7CYHkIg+UhDJaHMFgewmB5CIPlIYx1eRwXwmAwUx4MxgpGPcnhWZ9Wxbo8Tz+2tM76rDsYipHUtXv5Wp/+z7q8fsHOeq2prVkPOTBMD7Q06s1G0jfQ+jxiXV7zJmX5/fyDRC41wIwN0x1yib7wR8mkrC4fync336ZGaTq6q87Nm+0uYLE4+NaGOnRqs1ymb2vWpS/p5+zS5TxiPb8Uo6ZMI32E4ky34Pbt23Q6HcUJpjk8hsCXNTCS232yntvzAiI5AZGcHpP1QW5nH6UzGGOmjHyKtEiCT4YIg+UhDJaHMFgewmB5CIPlIQyWhzBYHsJgeQiD5SEMlocwWB7CYHkIg+UhDJaHMFgewmB5CIPlIQyWhzBYHsJgeQiD5SEMlocwjiyPRqNZnczUYXDkbSNJ0mx25IFqjizP4cHyEAbLQxgsD2GwPITB8hAGy0MYLA9hsDyEwfIQBstDGCwPYbA8hMHyEAbLQ5ieZ0BCjuTkZIVC0XkJSZKurq7nzp2zX1BQcMAjb+TIkZZm9A4AAGPGjLF3XLbHAeXNmjVLJBJ1XiISiTIze/NOxT6OA8oLCwuLifnNu/Ti4+NDQ0PtFxEsHFDeYwefUCicOXOmvSOCgmPKCw8Pj46OtnyOjY11yMPOYeUBAGbPni0UCkUi0bx58+wdCyz6xPvztBqzrEGnUZjUCqPRSJr0Nqm9CBJDZpEkKb3jLr3T8sezY7BoBIPG5TO4fMLTh83uA1P/2rOep2w13rmhvFuk1ijNDBadYBEEi2CwGGZjX+xsSWfQjXqjSW8y6k1GnYnrSoREcUPj+Dy3LqcRho195Bl05IXjUkm9gc5k8gRcjpv1qef7Mpo2rVKiMekNov7M0S96MVg06mOwg7wb5+RXf5AKgz08/fkUFw2DloeKxrstw54TxCRTvTlUy/vhyyZNO9NzgCuVhVKA7H6bi4sxdbaQykIplXciuwGwOG4+LpSVSCVtj5SEWfv8X0VPkdY2UHfLdGh7HWBzHdUcAMDNl2eiOx/+uI6yEimS99PBZie+i5uohxcFoI6brwuTxz2TI6GmOCrklV5VKBWEmx+PgrLsjrsfX95GL/9Z8RRp/yhUyLtwpNmtn6PdoXSDm5/r+aNUHHzQ5V3OlXkHutPodqgG2Qs6QfPq73rlexs81umhIKi5G42gtlIrCHCDWkqvUSily99LvFVm+xZ27yD3+7fbYQ/LhSuvpkRFOu6z7+4xk/TqEhXUIuDu2bvFao47ki+R+uNw3TlVxWqoRcBtVWhtNvhGekLKXK6QfPvDjtqHJQaDLjxk2DPJ8708+wEACq4cOpv/VdbLu788uKpZet9HGDx6RGZ8TJrlVzdvnTp5Zq9Wq4oIGzlq+HRIsQEA+EJu420lvPzhHnkapUnVZoB0q2IyGbO/eK2mtvilSe8sX3LQ2Zm/M3teS+sjAACDYGnaFcdyP5o25b2P1l+NHDTm6xOb5AoJAKChqerAkTXimOdW/v1wbNSzJ3K3wYjNAp2gKWR6rRridQ+mPIWR5QSruaT6/k2JtHZGxrqwkESei8cLE5c6O/MKruQAAGh0uslkSE352wD/wTQaTRz9nNlsqm+4AwC4/PNRN1fRM2Nf5XJcQ4LiE8WTIIVngeXMUCsgvjQSojy1wsSEJq+mtoggmCGBYstXOp0eODCmpraoI0F/v0jLB44zHwCg1akAANKWhyJhYEcaf78ISOFZYDoRUOVBvOaRJCCgTUDUrlWZTIbl7yV2XsjneXV8tnTXfAyNRuHtNaDjK4vlDCk8C3SCBkiIFVyI8jg8QqeF9bJnHs+TxXJ+ZeZvLloE0cOBzuHwDUZdx1edDu7doF5j5PAhtrNDlMflMwztJkiZ+wpD9Pp2D3cfD/df30QtldXxeD3c2bq7+dyuvGQ2my1zkpVXXoQUngW91siFKQ/iNY/rSrh4MAGc5sLw0GHhIcNyjm9sbWtUqVsvXj28I3vu9Zt53f8qKnK8UiX77uROkiTv3iu8fO0olOAAsFw1XL3Y3bwo+48Dt57HcyPkzWpXIZSWoFdmbb9SeGzf4XdrH5Z4CwYmxL4wIjGj+5+EhSSmTVh8tfB4wZVD7m4+mRnrdn+2AMBpjlY0qfnucPsmwW1JryhU3ryo9gkXwCuiz9JQIYkdzQ2Lg9gQBvfx2MBILg30xX58FEAjTQERcBuf4Z42nTh034Es6UO5h7/19jyTybj2g1Srq4xGPYNgAmt3/D7C4Nfm77VhnGs3p5rMXVTISNJqDP18w7Ne3t1VhrJaeb9gNssZ7rEBvQMSaQa7V1QNHh/QVQLLM60n0WpVTk7WO7wQBNOVb8tTcVcxAAD0Bh2LaaVbKYPB6lytfIzS0zWLtwfbLkDrUNF7rLhA/qDKxBP9WRrTFQ3ygDBiyAjo20tFY1vUKFc6qVdJ4daI+whKiYpJ6CkwR13vsbRXRC0PWjVtuqdIizCaVl1bvXziXIq6blLa6fbQtod8kTvHA+4TRXuhbtGomuXT3uhHWYlUd3c//ukjpgvHReBo3QCVTQqTtv3FLF8qC7XDQJOfT7aUXVUIAjx43o7QB1fRrJZUtwwZ7pqQ6k5x0fYZ4iWXGi5+K9OoAJ3F4gk4LA6T+hj+IDqNQSXRmPR6Fx4YOcmL72GHYar2HFwpeaivvKGouqUmmASDRRAsgmAyCCZBmvrivD40gmYymEwGo0lvMmpNJpMpOIobLuZ7+bLsFlJfmAGptUkvfaRXK4wahclMkvr2vvhEjeVMp9NoHD7BdWV4+bLdve1/tugT8jC940/aI9YxwPIQBstDGCwPYbA8hMHyEAbLQ5j/ALuT9S5Cvb/dAAAAAElFTkSuQmCC",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear grafo con persistencia\n",
    "print(\"üèóÔ∏è Creando grafo con persistencia...\")\n",
    "\n",
    "builder_persistente = StateGraph(EstadoPersonalizado)\n",
    "builder_persistente.add_node(\"tutor_personal\", agente_personalizado)\n",
    "builder_persistente.add_edge(START, \"tutor_personal\")\n",
    "builder_persistente.add_edge(\"tutor_personal\", END)\n",
    "\n",
    "# Compilar con checkpointer\n",
    "grafo_persistente = builder_persistente.compile(checkpointer=checkpointer_sqlite)\n",
    "\n",
    "print(\"‚úÖ Grafo con persistencia creado\")\n",
    "print(\"üß† El agente recordara conversaciones anteriores\")\n",
    "Image(grafo_persistente.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Sistema de conversacion con memoria listo\n"
     ]
    }
   ],
   "source": [
    "# Funcion para conversar con persistencia\n",
    "def conversar_con_memoria(mensaje: str, usuario_id: str = \"estudiante_1\"):\n",
    "    \"\"\"\n",
    "    Conversa con el agente que tiene memoria persistente.\n",
    "    \"\"\"\n",
    "    print(f\"\\nüë§ Tu: {mensaje}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    config = {\"configurable\": {\"thread_id\": usuario_id}}\n",
    "    entrada = {\"messages\": [HumanMessage(content=mensaje)]}\n",
    "    \n",
    "    try:\n",
    "        resultado = grafo_persistente.invoke(entrada, config=config)\n",
    "        \n",
    "        # Mostrar respuesta\n",
    "        respuesta = resultado[\"messages\"][-1].content\n",
    "        print(f\"ü§ñ Tutor: {respuesta}\")\n",
    "        \n",
    "        # Mostrar informacion persistente\n",
    "        print(f\"\\nüìä Info Persistente:\")\n",
    "        print(f\"   üë§ Usuario: {resultado.get('nombre_usuario', 'N/A')}\")\n",
    "        print(f\"   üéØ Intereses: {resultado.get('intereses', [])}\")\n",
    "        print(f\"   üìà Nivel: {resultado.get('nivel_experiencia', 'N/A')}\")\n",
    "        print(f\"   üî¢ Sesion: #{resultado.get('numero_sesion', 0)}\")\n",
    "        print(f\"   ‚ùì Preguntas: {resultado.get('preguntas_realizadas', 0)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(\"‚úÖ Sistema de conversacion con memoria listo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ DEMOSTRACION DE PERSISTENCIA\n",
      "============================================================\n",
      "\n",
      "üë§ Tu: Hola, me llamo Ana y me interesa mucho el machine learning\n",
      "--------------------------------------------------\n",
      "ü§ñ Tutor: ¬°Hola Ana! Es un placer conocerte. Me alegra saber que te interesa el machine learning, es un campo fascinante y muy relevante en la actualidad. \n",
      "\n",
      "El machine learning, o aprendizaje automatico, es una rama de la inteligencia artificial que permite a las computadoras aprender de los datos y mejorar su rendimiento con el tiempo sin ser programadas explicitamente para cada tarea. \n",
      "\n",
      "Para comenzar, ¬øtienes alguna area especifica dentro del machine learning que te gustaria explorar? Por ejemplo, ¬øte interesa mas la teoria, la programacion, o quizas aplicaciones practicas como el reconocimiento de imagenes o el procesamiento de lenguaje natural? Estoy aqui para ayudarte a descubrir mas sobre este tema y guiarte en tu aprendizaje. ¬°Vamos a aprender juntos!\n",
      "\n",
      "üìä Info Persistente:\n",
      "   üë§ Usuario: Ana\n",
      "   üéØ Intereses: ['machine learning']\n",
      "   üìà Nivel: principiante\n",
      "   üî¢ Sesion: #1\n",
      "   ‚ùì Preguntas: 1\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Demostracion de persistencia\n",
    "print(\"üß™ DEMOSTRACION DE PERSISTENCIA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Conversacion 1\n",
    "conversar_con_memoria(\"Hola, me llamo Ana y me interesa mucho el machine learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üë§ Tu: que es lo que me interesa?\n",
      "--------------------------------------------------\n",
      "ü§ñ Tutor: ¬°Buena pregunta, Ana! Hasta ahora, has mencionado que te interesa el machine learning y, por extension, el deep learning. Estos son campos muy amplios y emocionantes, y hay muchas areas dentro de ellos que podrias explorar. \n",
      "\n",
      "Aqui hay algunas preguntas que podrian ayudarte a identificar mas especificamente tus intereses:\n",
      "\n",
      "1. **¬øTe gusta mas la teoria o la practica?**: ¬øPrefieres entender como funcionan los algoritmos y las matematicas detras del machine learning, o te gustaria mas trabajar en proyectos practicos y ver como se aplican estas tecnicas en el mundo real?\n",
      "\n",
      "2. **¬øHay alguna aplicacion especifica que te llame la atencion?**: Por ejemplo, ¬øte interesa el reconocimiento de imagenes, el procesamiento de lenguaje natural, la prediccion de datos, o quizas algo relacionado con la salud o los negocios?\n",
      "\n",
      "3. **¬øTe gustaria aprender a programar?**: Si aun no tienes experiencia en programacion, aprender a usar lenguajes como Python puede ser muy util, ya que es el lenguaje mas comunmente utilizado en machine learning y deep learning.\n",
      "\n",
      "4. **¬øTe gustaria trabajar en proyectos colaborativos o individuales?**: Esto puede influir en como te gustaria aprender y que tipo de recursos buscar.\n",
      "\n",
      "Reflexionar sobre estas preguntas puede ayudarte a definir mejor tus intereses y a guiar tu aprendizaje en machine learning y deep learning. ¬°Estoy aqui para ayudarte en cada paso del camino! ¬øHay alguna de estas preguntas que te gustaria explorar mas?\n",
      "\n",
      "üìä Info Persistente:\n",
      "   üë§ Usuario: Ana\n",
      "   üéØ Intereses: ['machine learning', 'deep learning']\n",
      "   üìà Nivel: principiante\n",
      "   üî¢ Sesion: #3\n",
      "   ‚ùì Preguntas: 3\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Conversacion 2 - deberia recordar el nombre\n",
    "conversar_con_memoria(\"que es lo que me interesa?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üë§ Tu: Tambien me interesa la programacion en Python\n",
      "--------------------------------------------------\n",
      "ü§ñ Tutor: ¬°Genial, Ana! Python es un lenguaje de programacion muy popular en el campo del machine learning y el deep learning. Es conocido por su simplicidad y legibilidad, lo que lo hace ideal para principiantes. Ademas, tiene muchas bibliotecas poderosas que facilitan el trabajo con datos y la construccion de modelos de aprendizaje automatico.\n",
      "\n",
      "Aqui hay algunas bibliotecas de Python que son especialmente utiles para el machine learning y el deep learning:\n",
      "\n",
      "1. **NumPy**: Es fundamental para el manejo de arreglos y operaciones matematicas. Te ayudara a trabajar con datos numericos de manera eficiente.\n",
      "\n",
      "2. **Pandas**: Esta biblioteca es excelente para la manipulacion y analisis de datos. Te permite trabajar con estructuras de datos como DataFrames, que son muy utiles para manejar conjuntos de datos.\n",
      "\n",
      "3. **Matplotlib y Seaborn**: Estas bibliotecas son utiles para la visualizacion de datos. Te permiten crear graficos y visualizar patrones en tus datos.\n",
      "\n",
      "4. **Scikit-learn**: Es una de las bibliotecas mas populares para machine learning en Python. Ofrece herramientas para la clasificacion, regresion y agrupamiento, entre otros.\n",
      "\n",
      "5. **TensorFlow y Keras**: Estas son bibliotecas clave para el deep learning. TensorFlow es mas compleja y poderosa, mientras que Keras es una interfaz mas sencilla que se puede usar sobre TensorFlow para construir y entrenar modelos de deep learning.\n",
      "\n",
      "Si estas comenzando con Python, te recomendaria que empieces por aprender los conceptos basicos del lenguaje y luego vayas explorando estas bibliotecas. Hay muchos recursos en linea, como tutoriales y cursos, que pueden ayudarte a avanzar.\n",
      "\n",
      "¬°No dudes en preguntar si necesitas recomendaciones de recursos o si tienes alguna duda especifica sobre Python! Estoy aqui para ayudarte en tu camino de aprendizaje.\n",
      "\n",
      "üìä Info Persistente:\n",
      "   üë§ Usuario: Ana\n",
      "   üéØ Intereses: ['machine learning', 'deep learning', 'python']\n",
      "   üìà Nivel: principiante\n",
      "   üî¢ Sesion: #3\n",
      "   ‚ùì Preguntas: 3\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Conversacion 3 - deberia recordar todo el contexto\n",
    "conversar_con_memoria(\"Tambien me interesa la programacion en Python\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
